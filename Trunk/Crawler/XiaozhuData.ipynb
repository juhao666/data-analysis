{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "\n",
    "import urllib.request as urlrequest\n",
    "from bs4 import BeautifulSoup\n",
    "import time,random\n",
    "import codecs\n",
    "\n",
    "url = 'http://cd.xiaozhu.com/search-duanzufang-p{}-0/'\n",
    "proxy = urlrequest.ProxyHandler({'https':'94.41.39.73:53281'})\n",
    "opener = urlrequest.build_opener(proxy)\n",
    "\n",
    "#eader =  'Mozilla/5.0 (Windows NT 6.1; rv:57.0) Gecko/20100101 Firefox/57.0'\n",
    "header ={  \n",
    "    \"Connection\": \"keep-alive\",  \n",
    "    \"Upgrade-Insecure-Requests\": \"1\",  \n",
    "    \"User-Agent\": \"Mozilla/5.0\",  \n",
    "    \"Accept\":\" text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",  \n",
    "    \"Accept-Encoding\": \"utf-8\"\n",
    "}; \n",
    "\n",
    "#opener.addheaders = header\n",
    "urlrequest.install_opener(opener)\n",
    "\n",
    "#with open('data/xiaozhu_hotels.txt','w',encoding = 'utf-8') as outputfile:\n",
    "with codecs.open('data/xiaozhu_hotels.txt','w','utf-8') as outputfile:\n",
    "    for i in range(1,10):\n",
    "        time.sleep(random.uniform(1,5))\n",
    "        start = url.format(i)\n",
    "        req = urlrequest.Request(url=start, headers=header);  \n",
    "        crawl_context = urlrequest.urlopen(req).read()\n",
    "        html_context = crawl_context.decode('utf-8')\n",
    "        page_soup = BeautifulSoup(html_context,'html.parser')\n",
    "        all_items = page_soup.find_all(class_='resule_img_a')\n",
    "        for each_item in all_items:\n",
    "            #print(each_item)\n",
    "            href = each_item.get('href')\n",
    "            #print(href)\n",
    "            title = each_item.find('img')['alt']\n",
    "            #print(title)        \n",
    "            req2 = urlrequest.Request(url=href, headers=header);  \n",
    "            detail_context = urlrequest.urlopen(req2).read().decode('utf-8')\n",
    "            soup = BeautifulSoup(detail_context,'html.parser')\n",
    "            addr = soup.find(class_='pr5').string\n",
    "            score = None\n",
    "            if soup.find(class_='top_bar_w2 border_right_none').find(class_='score-rate') is not None:\n",
    "                score = soup.find(class_='top_bar_w2 border_right_none').find(class_='score-rate').string\n",
    "            #rint(addr)\n",
    "            #print('{}  {}  {} {}'.format(href,title,addr,score))\n",
    "            outputfile.write('{}\\t{}\\t{}\\t{}\\n'.format(href,title,addr,score))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
